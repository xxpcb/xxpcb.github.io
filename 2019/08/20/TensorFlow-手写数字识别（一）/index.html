<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>TensorFlow-手写数字识别（一） | 码农爱学习的博客</title><meta name="keywords" content="TensorFlow,MNIST"><meta name="author" content="xxpcb"><meta name="copyright" content="xxpcb"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="本篇文章通过TensorFlow搭建最基础的全连接网络，使用MNIST数据集实现基础的模型训练和测试。 MNIST数据集MNIST数据集 ：包含7万张黑底白字手写数字图片，其中55000张为训练集，5000张为验证集，10000张为测试集。每张图片大小为28X28像素，图片中纯黑色像素值为0，纯白色像素值为1。数据集的标签是长度为10的一维数组，数组中每个元素索引号表示对应数字出现的概率 。">
<meta property="og:type" content="article">
<meta property="og:title" content="TensorFlow-手写数字识别（一）">
<meta property="og:url" content="http://xxpcb.gitee.io/2019/08/20/TensorFlow-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%B8%80%EF%BC%89/index.html">
<meta property="og:site_name" content="码农爱学习的博客">
<meta property="og:description" content="本篇文章通过TensorFlow搭建最基础的全连接网络，使用MNIST数据集实现基础的模型训练和测试。 MNIST数据集MNIST数据集 ：包含7万张黑底白字手写数字图片，其中55000张为训练集，5000张为验证集，10000张为测试集。每张图片大小为28X28像素，图片中纯黑色像素值为0，纯白色像素值为1。数据集的标签是长度为10的一维数组，数组中每个元素索引号表示对应数字出现的概率 。">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://xxpcb.gitee.io/img/default-cover.png">
<meta property="article:published_time" content="2019-08-20T11:54:56.000Z">
<meta property="article:modified_time" content="2019-08-20T12:30:16.610Z">
<meta property="article:author" content="xxpcb">
<meta property="article:tag" content="TensorFlow">
<meta property="article:tag" content="MNIST">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://xxpcb.gitee.io/img/default-cover.png"><link rel="shortcut icon" href="/img/favicon.png"><link rel="canonical" href="http://xxpcb.gitee.io/2019/08/20/TensorFlow-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%B8%80%EF%BC%89/"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload="this.media='all'"><script>const GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: undefined,
  translate: {"defaultEncoding":2,"translateDelay":0,"msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  noticeOutdate: undefined,
  highlight: {"plugin":"highlighjs","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  date_suffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'fancybox',
  Snackbar: undefined,
  source: {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js',
    justifiedGallery: {
      js: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js',
      css: 'https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css'
    },
    fancybox: {
      js: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js',
      css: 'https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css'
    }
  },
  isPhotoFigcaption: false,
  islazyload: false,
  isanchor: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: 'TensorFlow-手写数字识别（一）',
  isPost: true,
  isHome: false,
  isHighlightShrink: false,
  isToc: true,
  postUpdate: '2019-08-20 20:30:16'
}</script><noscript><style type="text/css">
  #nav {
    opacity: 1
  }
  .justified-gallery img {
    opacity: 1
  }

  #recent-posts time,
  #post-meta time {
    display: inline !important
  }
</style></noscript><script>(win=>{
    win.saveToLocal = {
      set: function setWithExpiry(key, value, ttl) {
        if (ttl === 0) return
        const now = new Date()
        const expiryDay = ttl * 86400000
        const item = {
          value: value,
          expiry: now.getTime() + expiryDay,
        }
        localStorage.setItem(key, JSON.stringify(item))
      },

      get: function getWithExpiry(key) {
        const itemStr = localStorage.getItem(key)

        if (!itemStr) {
          return undefined
        }
        const item = JSON.parse(itemStr)
        const now = new Date()

        if (now.getTime() > item.expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return item.value
      }
    }
  
    win.getScript = url => new Promise((resolve, reject) => {
      const script = document.createElement('script')
      script.src = url
      script.async = true
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    })
  
      win.activateDarkMode = function () {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      win.activateLightMode = function () {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }
      const t = saveToLocal.get('theme')
    
          if (t === 'dark') activateDarkMode()
          else if (t === 'light') activateLightMode()
        
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        if (asideStatus === 'hide') {
          document.documentElement.classList.add('hide-aside')
        } else {
          document.documentElement.classList.remove('hide-aside')
        }
      }
    
    const fontSizeVal = saveToLocal.get('global-font-size')
    if (fontSizeVal !== undefined) {
      document.documentElement.style.setProperty('--global-font-size', fontSizeVal + 'px')
    }
    
    const detectApple = () => {
      if (GLOBAL_CONFIG_SITE.isHome && /iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)){
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
    })(window)</script><meta name="generator" content="Hexo 5.4.0"></head><body><div id="loading-box"><div class="loading-left-bg"></div><div class="loading-right-bg"></div><div class="spinner-box"><div class="configure-border-1"><div class="configure-core"></div></div><div class="configure-border-2"><div class="configure-core"></div></div><div class="loading-word">加载中...</div></div></div><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img is-center"><img src="/img/logo.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">75</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">24</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image: url('/img/default-cover.png')"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">码农爱学习的博客</a></span><div id="menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fas fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fas fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">TensorFlow-手写数字识别（一）</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2019-08-20T11:54:56.000Z" title="发表于 2019-08-20 19:54:56">2019-08-20</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2019-08-20T12:30:16.610Z" title="更新于 2019-08-20 20:30:16">2019-08-20</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/TensorFlow/">TensorFlow</a></span></div><div class="meta-secondline"></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><p>本篇文章通过TensorFlow搭建最基础的全连接网络，使用MNIST数据集实现基础的模型训练和测试。</p>
<h1 id="MNIST数据集"><a href="#MNIST数据集" class="headerlink" title="MNIST数据集"></a>MNIST数据集</h1><p><strong>MNIST数据集</strong> ：包含7万张<strong>黑底白字</strong>手写数字图片，其中<strong>55000张为训练集</strong>，<strong>5000张为验证集</strong>，<strong>10000张为测试集</strong>。<br>每张图片大小为<strong>28X28</strong>像素，图片中纯黑色像素值为0，纯白色像素值为1。<br>数据集的标签是长度为10的一维数组，数组中每个元素索引号表示对应数字出现的概率 。</p>
<span id="more"></span>

<p>在将MNIST数据集作为输入喂入神经网络时，需先将数据集中每张图片变为长度784 一维数组，将该数组作为神经网络输入特征喂入神经网络。</p>
<p>例如：</p>
<p>一张数字手写体图片变成长度为 784 的一维数组<code>[0.0.0.0.0.231 0.235 0.459……0.219 0.0.0.0.]</code>输入神经网络。<br>该图片对应的标签为<code>[0.0.0.0.0.0.1.0.0.0]</code>，标签中索引号为 6 的元素为 1，表示是数字 6 出现的概率为 100%，则该图片对应的识别结果是 6。</p>
<p>使用input_data 模块中的<code>read_data_sets()</code>函数加载MNIST数据集：  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;./data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Extracting ./data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting ./data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting ./data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting ./data/t10k-labels-idx1-ubyte.gz</span><br></pre></td></tr></table></figure>

<p>在 <code>read_data_sets()</code>函数中有两个参数，第一个参数表示数据集存放路径，第二个参数表示数据集的存取形式。<br>当第二个参数为 Ture 时，表示以独热码形式存取数据集。<br><code>read_data_sets()</code>函数运行时，会检查指定路径内是否已经有数据集，若指定路径中没有数据集，则自动下载，<br>并将MNIST数据集分为<strong>训练集train</strong>、<strong>验证集validation</strong>和<strong>测试集test</strong>存放。</p>
<h2 id="MNIST数据集结构"><a href="#MNIST数据集结构" class="headerlink" title="MNIST数据集结构"></a>MNIST数据集结构</h2><p>在 Tensorflow中用以下函数返回子集样本数：</p>
<p>① 返回训练集train样本数</p>
<p>print(“train data size:”,mnist.train.num_examples)</p>
<p>② 返回验证集validation样本数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;validation data size:&quot;</span>,mnist.validation.num_examples)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">validation data size: 5000</span><br></pre></td></tr></table></figure>

<p>③ 返回测试集test样本数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&quot;test data size:&quot;</span>,mnist.test.num_examples)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">test data size: 10000</span><br></pre></td></tr></table></figure>

<h2 id="数据集标签"><a href="#数据集标签" class="headerlink" title="数据集标签"></a>数据集标签</h2><p>例如：<br>在MNIST数据集中，若想要查看训练集中第0张图片的标签，则使用如下函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mnist.train.labels[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])</span><br></pre></td></tr></table></figure>



<h2 id="MNIST数据集图片像素值"><a href="#MNIST数据集图片像素值" class="headerlink" title="MNIST数据集图片像素值"></a>MNIST数据集图片像素值</h2><p>例如：<br>在MNIST数据集中，若想要查看训练集中第0张图片像素值，则使用如下函数：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mnist.train.images[<span class="number">0</span>]</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">array([0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       ...略去中间部分，太多了</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.34901962, 0.9843138 , 0.9450981 ,</span><br><span class="line">       0.3372549 , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.01960784,</span><br><span class="line">       0.8078432 , 0.96470594, 0.6156863 , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.01568628, 0.45882356, 0.27058825,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        , 0.        ,</span><br><span class="line">       0.        , 0.        , 0.        , 0.        ], dtype=float32)</span><br></pre></td></tr></table></figure>



<h2 id="将数据输入神经网络"><a href="#将数据输入神经网络" class="headerlink" title="将数据输入神经网络"></a>将数据输入神经网络</h2><p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">BATCH_SIZE = <span class="number">200</span></span><br><span class="line">xs,ys = mnist.train.next_batch(BATCH_SIZE)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;xs shape:&quot;</span>,xs.shape)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;ys shape:&quot;</span>,ys.shape)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">xs shape: (200, 784)</span><br><span class="line">ys shape: (200, 10)</span><br></pre></td></tr></table></figure>

<p>其中，<code>mnist.train.next_batch()</code>函数包含一个参数<code>BATCH_SIZE</code>，表示随机从训练集中抽取<code>BATCH_SIZE</code>个样本输入神经网络，并将样本的像素值和标签分别赋给<code>xs</code>和<code>ys</code>。<br>在本例中，<code>BATCH_SIZE</code>设置为200，表示一次将200个样本的像素值和标签分别赋值给<code>xs</code>和<code>ys</code>，故<code>xs</code>的形状为(200,784)，对应的<code>ys</code>的形状为(200,10)。</p>
<h1 id="TensorFlow模型搭建基础"><a href="#TensorFlow模型搭建基础" class="headerlink" title="TensorFlow模型搭建基础"></a>TensorFlow模型搭建基础</h1><h2 id="实现“MNIST数据集手写数字识别-”的常用函数"><a href="#实现“MNIST数据集手写数字识别-”的常用函数" class="headerlink" title="实现“MNIST数据集手写数字识别 ”的常用函数"></a>实现“MNIST数据集手写数字识别 ”的常用函数</h2><p>① <code>tf.get_collection(&quot;&quot;)</code> 函数表示从collection集合中取出全部变量生成一个列表 。</p>
<p>② <code>tf.add()</code>函数表示将参数列表中对应元素相加 。<br>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line">x=tf.constant([[<span class="number">1</span>,<span class="number">2</span>],[<span class="number">1</span>,<span class="number">2</span>]])</span><br><span class="line">y=tf.constant([[<span class="number">1</span>,<span class="number">1</span>],[<span class="number">1</span>,<span class="number">2</span>]])</span><br><span class="line">z=tf.add(x,y)</span><br><span class="line"><span class="keyword">with</span> tf.Session( ) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(z))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[[2 3]</span><br><span class="line"> [2 4]]</span><br></pre></td></tr></table></figure>

<p>③ <code>tf.cast(x,dtype)</code>函数表示将参数x转换为指定数据类型 </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">A = tf.convert_to_tensor(np.array([[<span class="number">1</span>,<span class="number">1</span>,<span class="number">2</span>,<span class="number">4</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">8</span>,<span class="number">5</span>]]))</span><br><span class="line"><span class="built_in">print</span>(A.dtype)</span><br><span class="line">b = tf.cast(A, tf.float32)</span><br><span class="line"><span class="built_in">print</span>(b.dtype)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">&lt;dtype: &#x27;int32&#x27;&gt;</span><br><span class="line">&lt;dtype: &#x27;float32&#x27;&gt;</span><br></pre></td></tr></table></figure>

<p>从输出结果看出，将矩阵A由整数型变为32位浮点型。</p>
<p>④ <code>tf.equal()</code>函数表示对比两个矩阵或者向量的元素。若对应元素相等，则返回True,若对应元素不相等，则返回False。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">A = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>,<span class="number">6</span>]]</span><br><span class="line">B = [[<span class="number">1</span>,<span class="number">3</span>,<span class="number">4</span>,<span class="number">3</span>,<span class="number">2</span>]]</span><br><span class="line"><span class="keyword">with</span> tf.Session( ) <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.equal(A, B)))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[[ True  True  True False False]]</span><br></pre></td></tr></table></figure>

<p>在矩阵A和B中，第1、2、3个元素相等，第4、5个元素不等，故输出结果中，第1、2、3个元素取值为 True，第4、5个元素取值为 False。</p>
<p>⑤<code>tf.reduce_mean(x,axis)</code>函数表示求取矩阵或张量指定维度的平均值。</p>
<ul>
<li>若不指定第二个参数，则在所有元素中取平均值</li>
<li>若指定第二个参数为0，则在第一维元素上取平均值，即每一列求平均值</li>
<li>若指定第二个参数为1，则在第二维元素上取平均值，即每一行求平均值</li>
</ul>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = [[<span class="number">1.</span>, <span class="number">1.</span>],</span><br><span class="line">     [<span class="number">2.</span>, <span class="number">2.</span>]]</span><br><span class="line"></span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.reduce_mean(x)))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.reduce_mean(x,<span class="number">0</span>)))</span><br><span class="line">    <span class="built_in">print</span>(sess.run(tf.reduce_mean(x,<span class="number">1</span>)))</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">1.5</span><br><span class="line">[1.5 1.5]</span><br><span class="line">[1. 2.]</span><br></pre></td></tr></table></figure>

<p>⑥ <code>tf.argmax(x,axis)</code>函数表示返回指定维度axis下，参数<code>x</code>中最大值索引号。</p>
<p>例如：</p>
<p>在<code>tf.argmax([1,0,0],1)</code>函数中，axis为1，参数<code>x</code>为<code>[1,0,0]</code>，表示在参数<code>x</code>的第一个维度取最大值对应的索引号，故返回 0。</p>
<p>⑦ <code>os.path.join()</code>函数表示把参数字符串按照路径命名规则拼接。</p>
<p>例如：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line">os.path.join(<span class="string">&#x27;/hello/&#x27;</span>,<span class="string">&#x27;good/boy/&#x27;</span>,<span class="string">&#x27;doiido&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#x27;/hello/good/boy/doiido&#x27;</span><br></pre></td></tr></table></figure>

<p>⑧ <code>字符串.split()</code>函数表示定按照指定“拆分符”对字符串拆分，返回拆分列表。</p>
<p>例如：<br><code>&#39;./model/mnist_model-1001&#39;.split(&#39;/&#39;)[-1].split(&#39;-&#39;)[-1]</code><br>在该例子中，共进行两次拆分。</p>
<ul>
<li>拆分符为<code>/</code>，返回拆分列表，并提取列表中索引为-1 的元素即倒数第一个元素；</li>
<li>拆分符为<code>-</code>，返回拆分列表，并提取列表中索引为-1 的元素即倒数第一个元素，故函数返回值为 1001。</li>
</ul>
<p>⑨ <code>tf.Graph( ).as_default( )</code>函数表示将当前图设置成为默认图，并返回一个上下文管理器。 </p>
<p>该函数一般与with关键字搭配使用，应用于将已经定义好的神经网络在计算图中复现。</p>
<p>例如：<br><code>with tf.Graph().as_default() as g</code>，表示将在<code> Graph()</code>内定义的节点加入到<code>计算图g</code>中。</p>
<h2 id="神经网络模型的保存"><a href="#神经网络模型的保存" class="headerlink" title="神经网络模型的保存"></a>神经网络模型的保存</h2><p>在反向传播过程中，一般会间隔一定轮数保存一次神经网络模型，并产生三个文件:</p>
<ul>
<li>保存当前图结构的<code>.meta</code>文件</li>
<li>保存当前参数名的<code>.index</code>文件</li>
<li>保存当前参数的<code>.data</code>文件</li>
</ul>
<p>在Tensorflow中如下表示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">saver = tf.train.Saver()</span><br><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(STEPS):</span><br><span class="line">        <span class="keyword">if</span> i %  轮数 == <span class="number">0</span>:</span><br><span class="line">            saver.save(sess, os.path.join(MODEL_SAVE_PATH,MODEL_NAME), global_step=global_step)</span><br></pre></td></tr></table></figure>

<p>其中，<code>tf.train.Saver()</code>用来实例化<code>saver</code>对象。<br>上述代码表示，神经网络每循环规定的轮数，将神经网络模型中所有的参数等信息保存到指定的路径中，并在存放网络模型的文件夹名称中注明保存模型时的训练轮数。</p>
<h2 id="神经网络模型的加载"><a href="#神经网络模型的加载" class="headerlink" title="神经网络模型的加载"></a>神经网络模型的加载</h2><p>在测试网络效果时，需要将训练好的神经网络模型加载，在TensorFlow 中这样表示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">    ckpt = tf.train.get_checkpoint_state(存储路径)</span><br><span class="line">    <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">        saver.restore(sess, ckpt.model_checkpoint_path)</span><br></pre></td></tr></table></figure>

<p>在<code>with</code>结构中进行加载保存的神经网络模型，若<code>ckpt</code>和保存的模型在指定路径中存在，则将保存的神经网络模型加载到当前会话中。</p>
<h2 id="加载模型中参数的滑动平均值"><a href="#加载模型中参数的滑动平均值" class="headerlink" title="加载模型中参数的滑动平均值"></a>加载模型中参数的滑动平均值</h2><p>在保存模型时，若模型中采用滑动平均，则参数的滑动平均值会保存在相应文件中。通过实例化<code>saver</code>对象，实现参数滑动平均值的加载，<br>在TensorFlow中如下表示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ema = tf.train.ExponentialMovingAverage(滑动平均基数)</span><br><span class="line">ema_restore = ema.variables_to_restore()</span><br><span class="line">saver = tf.train.Saver(ema_restore)</span><br></pre></td></tr></table></figure>

<h2 id="神经网络模型准确率评估方法"><a href="#神经网络模型准确率评估方法" class="headerlink" title="神经网络模型准确率评估方法"></a>神经网络模型准确率评估方法</h2><p>在网络评估时，一般通过计算在一组数据上的识别准确率，评估神经网络的效果。在TensorFlow 中这样表示：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>),tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br></pre></td></tr></table></figure>

<ul>
<li><code>y</code>:表示在一组数据（即<code>batch_size</code>个数据）上神经网络模型的预测结果，<code>y</code>的形状为<code>[batch_size,10]</code>，每一行表示一张图片的识别结果。</li>
<li><code>tf.argmax()</code>:取出每张图片对应向量中最大值元素对应的索引值，组成长度为输入数据<code>batch_size</code>个的一维数组。</li>
<li><code>tf.equal()</code>:判断预测结果张量和实际标签张量的每个维度是否相等，若相等则返回 True，不相等则返回 False。</li>
<li><code>tf.cast()</code>:将得到的布尔型数值转化为实数型，再通过<code>tf.reduce_mean()</code>函数求平均值，最终得到神经网络模型在本组数据上的准确率。</li>
</ul>
<h1 id="网络模型分析"><a href="#网络模型分析" class="headerlink" title="网络模型分析"></a>网络模型分析</h1><p>神经网络包括前向传播过程和反向传播过程。</p>
<p>反向传播过程中用到的正则化、指数衰减学习率、滑动平均方法的设置、以及测试模块。</p>
<h2 id="前向传播过程（forward-py-）"><a href="#前向传播过程（forward-py-）" class="headerlink" title="前向传播过程（forward.py ）"></a>前向传播过程（forward.py ）</h2><p>前向传播过程完成神经网络的搭建，结构如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x, regularizer</span>):</span></span><br><span class="line">    w=</span><br><span class="line">    b=</span><br><span class="line">    y=</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span>(<span class="params">shape,  regularizer</span>):</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span>(<span class="params">shape</span>):</span></span><br></pre></td></tr></table></figure>

<p>前向传播过程中，需要定义神经网络中的参数<code>w</code>和偏置<code>b</code>，定义由输入到输出的网络结构。</p>
<p>通过定义函数<code>get_weight()</code>实现对参数<code>w</code>的设置，包括参数<code>w</code>的形状和是否正则化的标志。<br>同样，通过定义函数<code>get_bias()</code>实现对偏置<code>b</code>的设置。</p>
<h2 id="反向传播过程（-back-word-py-）"><a href="#反向传播过程（-back-word-py-）" class="headerlink" title="反向传播过程（ back word.py ）"></a>反向传播过程（ back word.py ）</h2><p>反向传播过程完成网络参数的训练，结构如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params"> mnist </span>):</span></span><br><span class="line">    x =  tf.placeholder(dtype,shape)</span><br><span class="line">    y_ =  tf.placeholder(dtype,shape)</span><br><span class="line">    <span class="comment">#定义前向传播函数</span></span><br><span class="line">    y = forward()</span><br><span class="line">    global_step =</span><br><span class="line">    loss =</span><br><span class="line">    train_step = tf.train .GradientDescentOptimizer( learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line">    <span class="comment">#实例化saver对象</span></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line">    <span class="keyword">with</span>  tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        <span class="comment">#初始化所有模型参数</span></span><br><span class="line">        tf.initialize_all_variables().run()</span><br><span class="line">        <span class="comment">#训练模型</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(STEPS):</span><br><span class="line">            sess.run(train_step, feed_dict=&#123;x: , y_: &#125;)</span><br><span class="line">            <span class="keyword">if</span> i %  轮数 == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span></span><br><span class="line">                saver.save( )</span><br></pre></td></tr></table></figure>

<p>反向传播过程中：</p>
<ul>
<li><p><code>tf.placeholder(dtype, shape)</code>：实现训练样本<code>x</code>和样本标签<code>y_</code>占位</p>
<ul>
<li>参数<code>dtype</code>表示数据的类型</li>
<li>参数<code>shape</code>表示数据的形状</li>
</ul>
</li>
<li><p><code>y</code>：定义的前向传播函数 forward</p>
</li>
<li><p><code>loss</code>：定义的损失函数，一般为预测值与样本标签的交叉熵（或均方误差）与正则化损失之和</p>
</li>
<li><p><code>train_step</code>：利用优化算法对模型参数进行优化</p>
<p>常用优化算法有<code>GradientDescentOptimizer</code>、<code>AdamOptimizer</code>、<code>MomentumOptimizer</code>，在上述代码中使用的<code>GradientDescentOptimizer</code>优化算法。</p>
</li>
</ul>
<p>接着实例化<code>saver</code>对象：</p>
<ul>
<li><code>tf.initialize_all_variables().run()</code>：实例化所有参数模型</li>
<li><code>sess.run( )</code>：实现模型的训练优化过程，并每间隔一定轮数保存一次模型</li>
</ul>
<h2 id="正则化、指数衰减学习率、滑动平均方法的设置"><a href="#正则化、指数衰减学习率、滑动平均方法的设置" class="headerlink" title="正则化、指数衰减学习率、滑动平均方法的设置"></a>正则化、指数衰减学习率、滑动平均方法的设置</h2><p>① 正则化项 regularization</p>
<p>当在前向传播过程中即<code>forward.py</code>文件中，设置正则化参数<code>regularization</code>为1 时，则表明在反向传播过程中优化模型参数时，需要在损失函数中加入正则化项。<br>结构如下：</p>
<p>首先，需要在前向传播过程即<code>forward.py</code>文件中加入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> regularizer != <span class="literal">None</span>: </span><br><span class="line">    tf.add_to_collection(<span class="string">&#x27;losses&#x27;</span>,tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br></pre></td></tr></table></figure>

<p>其次，需要在反向传播过程即<code>byackword.py</code>文件中加入</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y,labels=tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">cem = tf.reduce_mean(ce)</span><br><span class="line">loss = cem + tf.add_n(tf.get_collection(<span class="string">&#x27;losses&#x27;</span>))</span><br></pre></td></tr></table></figure>

<ul>
<li><code>tf.nn.sparse_softmax_cross_entropy_with_logits()</code>：表示<code>softmax()</code>函数与交叉熵一起使用。</li>
</ul>
<p>②指数衰减学习率</p>
<p>在训练模型时，使用指数衰减学习率可以使模型在训练的前期快速收敛接近较优解，又可以保证模型在训练后期不会有太大波动。</p>
<p>运用指数衰减学习率，需要在反向传播过程即<code>backword.py</code>文件中加入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">learning_rate = tf.train.exponential_decay(LEARNING_RATE_BASE,global_step,LEARNING_RATE_STEP, LEARNING_RATE_DECAY,staircase=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>③ 滑动平均</p>
<p>在模型训练时引入滑动平均可以使模型在测试数据上表现的更加健壮。</p>
<p>需要在反向传播过程即<code>backword.py</code>文件中加入：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ema = tf.train .ExponentialMovingAverage(MOVING_AVERAGE_DECAY,global_step)</span><br><span class="line">ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line"><span class="keyword">with</span> tf.control_dependencies([train_step, ema_op]):</span><br><span class="line">    train_op = tf.no_op(name=<span class="string">&#x27;train&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="测试过程（-test-py-）"><a href="#测试过程（-test-py-）" class="headerlink" title="测试过程（ test .py ）"></a>测试过程（ test .py ）</h2><p>当神经网络模型训练完成后，便可用于测试数据集，验证神经网络的性能。结构如下：</p>
<p>首先，制定模型测试函数<code>test()</code></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params"> mnist </span>):</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph( ).as_default( ) <span class="keyword">as</span> g:</span><br><span class="line">        </span><br><span class="line">    <span class="comment">#给x y_ 占位</span></span><br><span class="line">    x = tf.placeholder( dtype, , shape) )</span><br><span class="line">    y_ = tf.placeholder( dtype, , shape) )</span><br><span class="line"></span><br><span class="line">    <span class="comment">#前向传播得到预测结果y</span></span><br><span class="line">    y = mnist_forward.forward(x, <span class="literal">None</span> )</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#实例化可还原滑动平均的saver</span></span><br><span class="line">    ema =  tf.train.ExponentialMovingAverage(滑动衰减率)</span><br><span class="line">    ema_restore = ema.variables_to_restore()</span><br><span class="line">    saver = tf.train.Saver(ema_restore)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#计算正确率</span></span><br><span class="line">    correct_prediction = tf.equal(tf.argmax(y,<span class="number">1</span>),tf.argmax(y_,<span class="number">1</span>))</span><br><span class="line">    accuracy = tf.reduce_mean(tf.cast( correct_prediction,tf.float32))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="comment">#加载训练好的模型</span></span><br><span class="line">            ckpt = tf.train.get_checkpoint_state( 存储路径) )</span><br><span class="line">            <span class="comment">#如果已有ckpt模型则恢复</span></span><br><span class="line">            <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">                <span class="comment">#恢复会话</span></span><br><span class="line">                saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">                <span class="comment">#恢复轮数</span></span><br><span class="line">                global_ste = = ckpt.model_checkpoint_path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;- &#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">                <span class="comment">#计算准确率</span></span><br><span class="line">                accuracy_score = sess.run(accuracy, feed_dict=&#123;x: 测试数据 , y_: 测试数据标签 &#125;)</span><br><span class="line">                <span class="comment">#打印提示</span></span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;After %s training step(s), test accuracy=</span></span><br><span class="line"><span class="string">                %g&quot;</span> % (global_step, accuracy_score ))</span><br><span class="line">            <span class="comment">#如果没有模型</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&#x27;No checkpoint file found&#x27;</span>) <span class="comment"># # 模型不存在 提示</span></span><br><span class="line">                <span class="keyword">return</span></span><br></pre></td></tr></table></figure>

<p>其次，制定<code>main()</code>函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    <span class="comment">#加载测试数据集</span></span><br><span class="line">    mnist = input_data.read_data_sets (<span class="string">&quot;./data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    <span class="comment">#调用定义好的测试函数test ()</span></span><br><span class="line">    test(mnist)</span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>

<p>通过对测试数据的预测得到准确率，从而判断出训练出的神经网络模型的性能好坏。</p>
<p>当准确率低时，可能原因有模型需要改进，或者是训练数据量太少导致过拟合。</p>
<h1 id="网络模型搭建与测试"><a href="#网络模型搭建与测试" class="headerlink" title="网络模型搭建与测试"></a>网络模型搭建与测试</h1><p>实现手写体MNIST数据集的识别任务，共分为三个模块文件，分别是:</p>
<ul>
<li>描述网络结构的前向传播过程文件（mnist_forward.py)</li>
<li>描述网络参数优化方法的反向传播过程文件（mnist_backward.py）、  </li>
<li>验证模型准确率的测试过程文件（mnist_test.py ）。</li>
</ul>
<h2 id="前向传播过程文件（-mnist-forward-py-）"><a href="#前向传播过程文件（-mnist-forward-py-）" class="headerlink" title="前向传播过程文件（ mnist_forward.py ）"></a>前向传播过程文件（ mnist_forward.py ）</h2><p>在前向传播过程中，需要定义网络模型输入层个数、隐藏层节点数、输出层个数，定义网络参数 w、偏置 b，定义由输入到输出的神经网络架构。</p>
<p>实现手写体MNIST数据集的识别任务前向传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">INPUT_NODE = <span class="number">784</span></span><br><span class="line">OUTPUT_NODE = <span class="number">10</span></span><br><span class="line">LAYER1_NODE = <span class="number">500</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_weight</span>(<span class="params">shape, regularizer</span>):</span></span><br><span class="line">    w = tf.Variable(tf.truncated_normal(shape,stddev=<span class="number">0.1</span>))</span><br><span class="line">    <span class="keyword">if</span> regularizer != <span class="literal">None</span>: tf.add_to_collection(<span class="string">&#x27;losses&#x27;</span>, tf.contrib.layers.l2_regularizer(regularizer)(w))</span><br><span class="line">    <span class="keyword">return</span> w</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_bias</span>(<span class="params">shape</span>):</span>  </span><br><span class="line">    b = tf.Variable(tf.zeros(shape))  </span><br><span class="line">    <span class="keyword">return</span> b</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">x, regularizer</span>):</span></span><br><span class="line">    w1 = get_weight([INPUT_NODE, LAYER1_NODE], regularizer)</span><br><span class="line">    b1 = get_bias([LAYER1_NODE])</span><br><span class="line">    y1 = tf.nn.relu(tf.matmul(x, w1) + b1)</span><br><span class="line"></span><br><span class="line">    w2 = get_weight([LAYER1_NODE, OUTPUT_NODE], regularizer)</span><br><span class="line">    b2 = get_bias([OUTPUT_NODE])</span><br><span class="line">    y = tf.matmul(y1, w2) + b2</span><br><span class="line">    <span class="keyword">return</span> y</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>由上述代码可知，在前向传播过程中，规定网络:</p>
<ul>
<li><p><code>输入结点</code>：784个（代表每张输入图片的像素个数）</p>
</li>
<li><p><code>隐藏层节点</code>：500 个</p>
</li>
<li><p><code>输出节点</code>：10个（表示输出为数字 0-9的十分类）</p>
</li>
<li><p><code>w1</code>：由输入层到隐藏层的参数,形状为<code>[784,500]</code></p>
</li>
<li><p><code>w2</code>：由隐藏层到输出层的参数，形状为<code>[500,10]</code><br>（参数满足截断正态分布，并使用正则化，将每个参数的正则化损失加到总损失中）</p>
</li>
<li><p><code>b1</code>：由输入层到隐藏层的偏置，形状为长度为 500的一维数组</p>
</li>
<li><p><code>b2</code>：由隐藏层到输出层的偏置，形状为长度为10的一维数组，初始化值为全 0。</p>
</li>
<li><p><code>y1</code>：隐藏层输出，由前向传播结构第一层为输入<code>x</code>与参数<code>w1</code>矩阵相乘加上偏置<code>b1</code>，再经过<code>relu</code>函数得到</p>
</li>
<li><p><code>y</code>：输出，由前向传播结构第二层为隐藏层输出<code>y1</code>与参数<code>w2</code>矩阵相乘加上偏置<code>b2</code>得到<br>（由于输出<code>y</code>要经过<code>softmax</code>函数，使其符合概率分布，故输出<code>y</code>不经过<code>relu</code>函数）</p>
</li>
</ul>
<h2 id="反向传播过程文件（mnist-backward-py-）"><a href="#反向传播过程文件（mnist-backward-py-）" class="headerlink" title="反向传播过程文件（mnist_backward.py ）"></a>反向传播过程文件（mnist_backward.py ）</h2><p>反向传播过程实现利用训练数据集对神经网络模型训练，通过降低损失函数值，实现网络模型参数的优化，从而得到准确率高且泛化能力强的神经网络模型。</p>
<p>实现手写体MNIST数据集的识别任务反向传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> mnist_forward</span><br><span class="line"><span class="keyword">import</span> os</span><br><span class="line"></span><br><span class="line">BATCH_SIZE = <span class="number">200</span></span><br><span class="line">LEARNING_RATE_BASE = <span class="number">0.1</span></span><br><span class="line">LEARNING_RATE_DECAY = <span class="number">0.99</span></span><br><span class="line">REGULARIZER = <span class="number">0.0001</span></span><br><span class="line">STEPS = <span class="number">500</span> <span class="comment">#50000</span></span><br><span class="line">MOVING_AVERAGE_DECAY = <span class="number">0.99</span></span><br><span class="line">MODEL_SAVE_PATH=<span class="string">&quot;./model/&quot;</span></span><br><span class="line">MODEL_NAME=<span class="string">&quot;mnist_model&quot;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">backward</span>(<span class="params">mnist</span>):</span></span><br><span class="line"></span><br><span class="line">    x = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line">    y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line">    y = mnist_forward.forward(x, REGULARIZER)</span><br><span class="line">    global_step = tf.Variable(<span class="number">0</span>, trainable=<span class="literal">False</span>)</span><br><span class="line"></span><br><span class="line">    ce = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y, labels=tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">    cem = tf.reduce_mean(ce)</span><br><span class="line">    loss = cem + tf.add_n(tf.get_collection(<span class="string">&#x27;losses&#x27;</span>))</span><br><span class="line"></span><br><span class="line">    learning_rate = tf.train.exponential_decay(</span><br><span class="line">        LEARNING_RATE_BASE,</span><br><span class="line">        global_step,</span><br><span class="line">        mnist.train.num_examples / BATCH_SIZE, </span><br><span class="line">        LEARNING_RATE_DECAY,</span><br><span class="line">        staircase=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">    train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)</span><br><span class="line"></span><br><span class="line">    ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)</span><br><span class="line">    ema_op = ema.apply(tf.trainable_variables())</span><br><span class="line">    <span class="keyword">with</span> tf.control_dependencies([train_step, ema_op]):</span><br><span class="line">        train_op = tf.no_op(name=<span class="string">&#x27;train&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    saver = tf.train.Saver()</span><br><span class="line"></span><br><span class="line">    <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">        init_op = tf.global_variables_initializer()</span><br><span class="line">        sess.run(init_op)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(STEPS):</span><br><span class="line">            xs, ys = mnist.train.next_batch(BATCH_SIZE)</span><br><span class="line">            _, loss_value, step = sess.run([train_op, loss, global_step], feed_dict=&#123;x: xs, y_: ys&#125;)</span><br><span class="line">            <span class="keyword">if</span> i % <span class="number">1000</span> == <span class="number">0</span>:</span><br><span class="line">                <span class="built_in">print</span>(<span class="string">&quot;After %d training step(s), loss on training batch is %g.&quot;</span> % (step, loss_value))</span><br><span class="line">                saver.save(sess, os.path.join(MODEL_SAVE_PATH, MODEL_NAME), global_step=global_step)</span><br><span class="line">                </span><br><span class="line">                </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">&quot;./data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    backward(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">Extracting ./data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting ./data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting ./data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting ./data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">After 1 training step(s), loss on training batch is 3.47547.</span><br><span class="line">After 1001 training step(s), loss on training batch is 0.283958.</span><br><span class="line">After 2001 training step(s), loss on training batch is 0.304716.</span><br><span class="line">After 3001 training step(s), loss on training batch is 0.266811.</span><br><span class="line">...省略</span><br><span class="line">After 47001 training step(s), loss on training batch is 0.128592.</span><br><span class="line">After 48001 training step(s), loss on training batch is 0.125534.</span><br><span class="line">After 49001 training step(s), loss on training batch is 0.123577.</span><br></pre></td></tr></table></figure>

<p>由上述代码可知，在反向传播过程中:</p>
<ul>
<li>引入<code>tensorflow</code>、<code>input_data</code>、前向传播<code>mnist_forward</code> 和<code>os</code>模块</li>
<li>定义每轮喂入神经网络的图片数、初始学习率、学习率衰减率、正则化系数、训练轮数、模型保存路径以及模型保存名称等相关信息</li>
<li>反向传播函数<code>backword</code>中：<ul>
<li>读入<code>mnist</code>，用<code>placeholder</code>给<strong>训练数据</strong><code>x</code>和<strong>标签</strong><code>y_</code>占位</li>
<li>调用<code>mnist_forward</code>文件中的前向传播过程<code>forword()</code>函数，并设置正则化，计算训练数据集上的<strong>预测结果</strong><code>y</code></li>
<li>并给当前计算轮数计数器赋值，设定为不可训练类型</li>
<li>调用包含所有参数正则化损失的损失函数<code>loss</code>，并设定指数衰减学习率<code>learning_rate</code></li>
<li>使用梯度衰减算法对模型优化，降低损失函数，并定义参数的滑动平均</li>
<li>在<code>with</code>结构中:<ul>
<li>实现所有参数初始化</li>
<li>每次喂入<code>batch_size</code>组（即 200 组）训练数据和对应标签，循环迭代<code>steps</code>轮</li>
<li>并每隔 1000 轮打印出一次损失函数值信息，并将当前会话加载到指定路径</li>
</ul>
</li>
</ul>
</li>
<li>通过主函数<code>main()</code>，加载指定路径下的训练数据集，并调用规定的<code>backward()</code>函数训练模型</li>
</ul>
<h2 id="测试过程文件（mnist-test-py-）"><a href="#测试过程文件（mnist-test-py-）" class="headerlink" title="测试过程文件（mnist_ test .py ）"></a>测试过程文件（mnist_ test .py ）</h2><p>当训练完模型后，给神经网络模型输入测试集验证网络的准确性和泛化性。<br>注意，所用的测试集和训练集是相互独立的。</p>
<p>实现手写体MNIST数据集的识别任务测试传播过程如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> tensorflow.examples.tutorials.mnist <span class="keyword">import</span> input_data</span><br><span class="line"><span class="keyword">import</span> mnist_forward</span><br><span class="line"><span class="keyword">import</span> mnist_backward</span><br><span class="line">TEST_INTERVAL_SECS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span>(<span class="params">mnist</span>):</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default() <span class="keyword">as</span> g:</span><br><span class="line">        x = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.INPUT_NODE])</span><br><span class="line">        y_ = tf.placeholder(tf.float32, [<span class="literal">None</span>, mnist_forward.OUTPUT_NODE])</span><br><span class="line">        y = mnist_forward.forward(x, <span class="literal">None</span>)</span><br><span class="line"></span><br><span class="line">        ema = tf.train.ExponentialMovingAverage(mnist_backward.MOVING_AVERAGE_DECAY)</span><br><span class="line">        ema_restore = ema.variables_to_restore()</span><br><span class="line">        saver = tf.train.Saver(ema_restore)</span><br><span class="line"></span><br><span class="line">        correct_prediction = tf.equal(tf.argmax(y, <span class="number">1</span>), tf.argmax(y_, <span class="number">1</span>))</span><br><span class="line">        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))</span><br><span class="line"></span><br><span class="line">        <span class="keyword">while</span> <span class="literal">True</span>:</span><br><span class="line">            <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">                ckpt = tf.train.get_checkpoint_state(mnist_backward.MODEL_SAVE_PATH)</span><br><span class="line">                <span class="keyword">if</span> ckpt <span class="keyword">and</span> ckpt.model_checkpoint_path:</span><br><span class="line">                    saver.restore(sess, ckpt.model_checkpoint_path)</span><br><span class="line">                    global_step = ckpt.model_checkpoint_path.split(<span class="string">&#x27;/&#x27;</span>)[-<span class="number">1</span>].split(<span class="string">&#x27;-&#x27;</span>)[-<span class="number">1</span>]</span><br><span class="line">                    accuracy_score = sess.run(accuracy, feed_dict=&#123;x: mnist.test.images, y_: mnist.test.labels&#125;)</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&quot;After %s training step(s), test accuracy = %g&quot;</span> % (global_step, accuracy_score))</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    <span class="built_in">print</span>(<span class="string">&#x27;No checkpoint file found&#x27;</span>)</span><br><span class="line">                    <span class="keyword">return</span></span><br><span class="line">            time.sleep(TEST_INTERVAL_SECS)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span>():</span></span><br><span class="line">    mnist = input_data.read_data_sets(<span class="string">&quot;./data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line">    test(mnist)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    main()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">Extracting ./data/train-images-idx3-ubyte.gz</span><br><span class="line">Extracting ./data/train-labels-idx1-ubyte.gz</span><br><span class="line">Extracting ./data/t10k-images-idx3-ubyte.gz</span><br><span class="line">Extracting ./data/t10k-labels-idx1-ubyte.gz</span><br><span class="line">After 49001 training step(s), test accuracy = 0.98</span><br></pre></td></tr></table></figure>

<p>在上述代码中，</p>
<ul>
<li>引入time模块、tensorflow、input_data、前向传播mnist_forward、反向传播 mnist_backward 模块和 os 模块</li>
<li>规定程序 5 秒的循环间隔时间</li>
<li>定义测试函数<code>test()</code>,读入mnist数据集:<ul>
<li>利用<code>tf.Graph()</code>复现之前定义的计算图</li>
<li>利用<code>placeholder</code>给训练数据<code>x</code>和标签<code>y_</code>占位</li>
<li>调用mnist_forward文件中的前向传播过程<code>forword()函数</code>，计算训练数据集上的预测结果<code>y</code></li>
<li>实例化具有滑动平均的<code>saver</code>对象，从而在会话被加载时模型中的所有参数被赋值为各自的滑动平均值，增强模型的稳定性</li>
<li>计算模型在测试集上的准确率</li>
<li>在<code>with</code>结构中，加载指定路径下的<code>ckpt</code>:<ul>
<li>若模型存在，则加载出模型到当前对话，在测试数据集上进行准确率验证，并打印出当前轮数下的准确率</li>
<li>若模型不存在，则打印出模型不存在的提示，从而<code>test()</code>函数完成</li>
</ul>
</li>
</ul>
</li>
<li>通过主函数<code>main()</code>，加载指定路径下的测试数据集，并调用规定的<code>test</code>函数，进行模型在测试集上的准确率验证</li>
</ul>
<p>从上面的运行结果可以看出，最终在测试集上的准确率在98%，模型训练mnist_backward.py与模型测试mnist_test.py可同时执行，这里可以更加直观看出：随着训练轮数的增加，网络模型的损失函数值在不断降低，并且在测试集上的准确率在不断提升，有较好的泛化能力。</p>
<p>参考：<a target="_blank" rel="noopener" href="https://www.icourse163.org/course/PKU-1002536002?tid=1002700003">人工智能实践：Tensorflow笔记</a></p>
</article><div><div style="text-align:center;color: #ccc;font-size:14px;font-family: cursive;">-------------&#x7EB8;&#x77ED;&#x60C5;&#x957F; <i class="fa fa-umbrella"></i> &#x4E0B;&#x6B21;&#x518D;&#x89C1;-------------</div></div><div id="wechat_subscriber"><center><img id="wechat_subscriber_qcode" src="undefined" onerror="onerror=null;src='https://xxpcb-1259761082.cos.ap-shanghai.myqcloud.com/hexo/wxgzh.png'" alt="码农爱学习"></center><div>关注微信公众号，获取更多精彩~</div></div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">xxpcb</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="http://xxpcb.gitee.io/2019/08/20/TensorFlow-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%B8%80%EF%BC%89/">http://xxpcb.gitee.io/2019/08/20/TensorFlow-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%B8%80%EF%BC%89/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="http://xxpcb.gitee.io" target="_blank">码农爱学习的博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/TensorFlow/">TensorFlow</a><a class="post-meta__tags" href="/tags/MNIST/">MNIST</a></div><div class="post_share"><div class="social-share" data-image="/img/default-cover.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/2019/08/20/TensorFlow-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%EF%BC%88%E4%BA%8C%EF%BC%89/"><img class="prev-cover" src="/img/default-cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">TensorFlow-手写数字识别（二）</div></div></a></div><div class="next-post pull-right"><a href="/2019/08/19/TensorFlow-%E5%B9%B3%E9%9D%A2%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88/"><img class="next-cover" src="/img/default-cover.png" onerror="onerror=null;src='/img/404.jpg'" alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">TensorFlow-平面曲线拟合</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i><span> 相关推荐</span></div><div class="relatedPosts-list"><div><a href="/2019/08/21/TensorFlow-手写数字识别（三）/" title="TensorFlow-手写数字识别（三）"><img class="cover" src="/img/default-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-08-21</div><div class="title">TensorFlow-手写数字识别（三）</div></div></a></div><div><a href="/2019/08/20/TensorFlow-手写数字识别（二）/" title="TensorFlow-手写数字识别（二）"><img class="cover" src="/img/default-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-08-20</div><div class="title">TensorFlow-手写数字识别（二）</div></div></a></div><div><a href="/2019/08/19/TensorFlow-平面曲线拟合/" title="TensorFlow-平面曲线拟合"><img class="cover" src="/img/default-cover.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2019-08-19</div><div class="title">TensorFlow-平面曲线拟合</div></div></a></div></div></div><hr/><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i><span> 评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="is-center"><div class="avatar-img"><img src="/img/logo.png" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info__name">xxpcb</div><div class="author-info__description"></div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">99</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">75</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">24</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener" href="https://gitee.com/xxpcb"><i class="fab fa-github"></i><span>Follow Me (gitee)</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/xxpcb" target="_blank" title="Github"><i class="fab fa-github"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">分享：单片机、嵌入式、ARM、Linux、C/C++、python等技术文章~ <img src="/img/wxgzh-card.png"></div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MNIST%E6%95%B0%E6%8D%AE%E9%9B%86"><span class="toc-number">1.</span> <span class="toc-text">MNIST数据集</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">MNIST数据集结构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A0%87%E7%AD%BE"><span class="toc-number">1.2.</span> <span class="toc-text">数据集标签</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#MNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E5%9B%BE%E7%89%87%E5%83%8F%E7%B4%A0%E5%80%BC"><span class="toc-number">1.3.</span> <span class="toc-text">MNIST数据集图片像素值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%B0%86%E6%95%B0%E6%8D%AE%E8%BE%93%E5%85%A5%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C"><span class="toc-number">1.4.</span> <span class="toc-text">将数据输入神经网络</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TensorFlow%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E5%9F%BA%E7%A1%80"><span class="toc-number">2.</span> <span class="toc-text">TensorFlow模型搭建基础</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%AE%9E%E7%8E%B0%E2%80%9CMNIST%E6%95%B0%E6%8D%AE%E9%9B%86%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB-%E2%80%9D%E7%9A%84%E5%B8%B8%E7%94%A8%E5%87%BD%E6%95%B0"><span class="toc-number">2.1.</span> <span class="toc-text">实现“MNIST数据集手写数字识别 ”的常用函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E4%BF%9D%E5%AD%98"><span class="toc-number">2.2.</span> <span class="toc-text">神经网络模型的保存</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8A%A0%E8%BD%BD"><span class="toc-number">2.3.</span> <span class="toc-text">神经网络模型的加载</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8A%A0%E8%BD%BD%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%8F%82%E6%95%B0%E7%9A%84%E6%BB%91%E5%8A%A8%E5%B9%B3%E5%9D%87%E5%80%BC"><span class="toc-number">2.4.</span> <span class="toc-text">加载模型中参数的滑动平均值</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%87%86%E7%A1%AE%E7%8E%87%E8%AF%84%E4%BC%B0%E6%96%B9%E6%B3%95"><span class="toc-number">2.5.</span> <span class="toc-text">神经网络模型准确率评估方法</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E5%88%86%E6%9E%90"><span class="toc-number">3.</span> <span class="toc-text">网络模型分析</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B%EF%BC%88forward-py-%EF%BC%89"><span class="toc-number">3.1.</span> <span class="toc-text">前向传播过程（forward.py ）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B%EF%BC%88-back-word-py-%EF%BC%89"><span class="toc-number">3.2.</span> <span class="toc-text">反向传播过程（ back word.py ）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%AD%A3%E5%88%99%E5%8C%96%E3%80%81%E6%8C%87%E6%95%B0%E8%A1%B0%E5%87%8F%E5%AD%A6%E4%B9%A0%E7%8E%87%E3%80%81%E6%BB%91%E5%8A%A8%E5%B9%B3%E5%9D%87%E6%96%B9%E6%B3%95%E7%9A%84%E8%AE%BE%E7%BD%AE"><span class="toc-number">3.3.</span> <span class="toc-text">正则化、指数衰减学习率、滑动平均方法的设置</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B%EF%BC%88-test-py-%EF%BC%89"><span class="toc-number">3.4.</span> <span class="toc-text">测试过程（ test .py ）</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E6%90%AD%E5%BB%BA%E4%B8%8E%E6%B5%8B%E8%AF%95"><span class="toc-number">4.</span> <span class="toc-text">网络模型搭建与测试</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B%E6%96%87%E4%BB%B6%EF%BC%88-mnist-forward-py-%EF%BC%89"><span class="toc-number">4.1.</span> <span class="toc-text">前向传播过程文件（ mnist_forward.py ）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD%E8%BF%87%E7%A8%8B%E6%96%87%E4%BB%B6%EF%BC%88mnist-backward-py-%EF%BC%89"><span class="toc-number">4.2.</span> <span class="toc-text">反向传播过程文件（mnist_backward.py ）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%B5%8B%E8%AF%95%E8%BF%87%E7%A8%8B%E6%96%87%E4%BB%B6%EF%BC%88mnist-test-py-%EF%BC%89"><span class="toc-number">4.3.</span> <span class="toc-text">测试过程文件（mnist_ test .py ）</span></a></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/2021/09/04/%E3%80%90i-MX6ULL%E3%80%91%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%912-%E6%96%B0%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E5%BC%80%E5%8F%91%E6%A8%A1%E6%9D%BF/" title="【i.MX6ULL】驱动开发2--新字符设备开发模板"><img src="/../img/imx/bsp2.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【i.MX6ULL】驱动开发2--新字符设备开发模板"/></a><div class="content"><a class="title" href="/2021/09/04/%E3%80%90i-MX6ULL%E3%80%91%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%912-%E6%96%B0%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E5%BC%80%E5%8F%91%E6%A8%A1%E6%9D%BF/" title="【i.MX6ULL】驱动开发2--新字符设备开发模板">【i.MX6ULL】驱动开发2--新字符设备开发模板</a><time datetime="2021-09-04T11:05:05.000Z" title="发表于 2021-09-04 19:05:05">2021-09-04</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/26/%E3%80%90i-MX6ULL%E3%80%91%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%911-%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E5%BC%80%E5%8F%91%E6%A8%A1%E6%9D%BF/" title="【i.MX6ULL】驱动开发1--字符设备开发模板"><img src="/../img/imx/bsp1.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="【i.MX6ULL】驱动开发1--字符设备开发模板"/></a><div class="content"><a class="title" href="/2021/08/26/%E3%80%90i-MX6ULL%E3%80%91%E9%A9%B1%E5%8A%A8%E5%BC%80%E5%8F%911-%E5%AD%97%E7%AC%A6%E8%AE%BE%E5%A4%87%E5%BC%80%E5%8F%91%E6%A8%A1%E6%9D%BF/" title="【i.MX6ULL】驱动开发1--字符设备开发模板">【i.MX6ULL】驱动开发1--字符设备开发模板</a><time datetime="2021-08-25T16:06:15.000Z" title="发表于 2021-08-26 00:06:15">2021-08-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/26/i-MX6ULL%E5%B5%8C%E5%85%A5%E5%BC%8FLinux%E5%BC%80%E5%8F%916-%E7%B3%BB%E7%BB%9F%E7%83%A7%E5%86%99%E5%88%B0eMMC%E4%B8%8E%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%EF%BC%81/" title="i.MX6ULL嵌入式Linux开发6-系统烧写到eMMC与遇到的坑！"><img src="/../img/imx/adapt6.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="i.MX6ULL嵌入式Linux开发6-系统烧写到eMMC与遇到的坑！"/></a><div class="content"><a class="title" href="/2021/08/26/i-MX6ULL%E5%B5%8C%E5%85%A5%E5%BC%8FLinux%E5%BC%80%E5%8F%916-%E7%B3%BB%E7%BB%9F%E7%83%A7%E5%86%99%E5%88%B0eMMC%E4%B8%8E%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91%EF%BC%81/" title="i.MX6ULL嵌入式Linux开发6-系统烧写到eMMC与遇到的坑！">i.MX6ULL嵌入式Linux开发6-系统烧写到eMMC与遇到的坑！</a><time datetime="2021-08-25T16:05:57.000Z" title="发表于 2021-08-26 00:05:57">2021-08-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/26/i-MX6ULL%E5%B5%8C%E5%85%A5%E5%BC%8FLinux%E5%BC%80%E5%8F%915-%E6%A0%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%8C%E5%96%84/" title="i.MX6ULL嵌入式Linux开发5-根文件系统完善"><img src="/../img/imx/adapt5.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="i.MX6ULL嵌入式Linux开发5-根文件系统完善"/></a><div class="content"><a class="title" href="/2021/08/26/i-MX6ULL%E5%B5%8C%E5%85%A5%E5%BC%8FLinux%E5%BC%80%E5%8F%915-%E6%A0%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E5%AE%8C%E5%96%84/" title="i.MX6ULL嵌入式Linux开发5-根文件系统完善">i.MX6ULL嵌入式Linux开发5-根文件系统完善</a><time datetime="2021-08-25T16:05:46.000Z" title="发表于 2021-08-26 00:05:46">2021-08-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/2021/08/26/i-MX6ULL%E5%B5%8C%E5%85%A5%E5%BC%8FLinux%E5%BC%80%E5%8F%914-%E6%A0%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA/" title="i.MX6ULL嵌入式Linux开发4-根文件系统构建"><img src="/../img/imx/adapt4.png" onerror="this.onerror=null;this.src='/img/404.jpg'" alt="i.MX6ULL嵌入式Linux开发4-根文件系统构建"/></a><div class="content"><a class="title" href="/2021/08/26/i-MX6ULL%E5%B5%8C%E5%85%A5%E5%BC%8FLinux%E5%BC%80%E5%8F%914-%E6%A0%B9%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA/" title="i.MX6ULL嵌入式Linux开发4-根文件系统构建">i.MX6ULL嵌入式Linux开发4-根文件系统构建</a><time datetime="2021-08-25T16:05:35.000Z" title="发表于 2021-08-26 00:05:35">2021-08-26</time></div></div></div></div></div></div></main><footer id="footer" style="background-image: url('/img/default-cover.png')"><div id="footer-wrap"><div class="copyright">&copy;2019 - 2021 By xxpcb</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">简</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script>var preloader = {
  endLoading: () => {
    document.body.style.overflow = 'auto';
    document.getElementById('loading-box').classList.add("loaded")
  },
  initLoading: () => {
    document.body.style.overflow = '';
    document.getElementById('loading-box').classList.remove("loaded")

  }
}
window.addEventListener('load',preloader.endLoading())</script><div class="js-pjax"><script>function loadValine () {
  function initValine () {
    const valine = new Valine(Object.assign({
      el: '#vcomment',
      appId: 'P6iS1Ip0yj2xKyDmnnT8mMrk-gzGzoHsz',
      appKey: 'bHIkuKIeQSpeQgKoE3vtEYKs',
      placeholder: 'Please leave your footprints',
      avatar: 'monsterid',
      meta: 'nick,mail,link'.split(','),
      pageSize: '10',
      lang: 'en',
      recordIP: false,
      serverURLs: '',
      emojiCDN: '',
      emojiMaps: "",
      enableQQ: false,
      path: window.location.pathname,
      requiredFields: ["nick,mail"],
      visitor: false
    }, null))
  }

  if (typeof Valine === 'function') initValine() 
  else getScript('https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js').then(initValine)
}

if ('Valine' === 'Valine' || !false) {
  if (false) btf.loadComment(document.getElementById('vcomment'),loadValine)
  else setTimeout(loadValine, 0)
} else {
  function loadOtherComment () {
    loadValine()
  }
}</script></div><script defer="defer" id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zIndex="-1" mobile="false" data-click="false"></script></div></body></html>